---
title:
layout: clean
permalink: /datasets/
published: true
---

# Datasets !

Here are some Datasets that I played a major role in curating.

---

### mmmCAD : Multi-modal Modification of CAD
<img src="/assets/images/datasets/mmmCAD.png" alt="Project Image" width="70%" />

Small scale data from [Communicating Design Intent Using Drawing and Text](https://dl.acm.org/doi/10.1145/3635636.3664261){:target="_blank"}. \[~100 man-hours\] One participant (Designer) communicate with another (Maker) to collaboratively re-create a precise 2D CAD design. The Designer is given a target design, and must use drawing and language to communicate to the maker, who makes the design using a CAD interface.

--- 

### LARC : Language-complete Abstract Reasoning Corpus
<img src="/assets/images/datasets/larc.jpeg" alt="Project Image" width="70%" />

From [Communicating Natural Programs to Humans and Machines](https://arxiv.org/abs/2106.07824){:target="_blank"}. \[~350 man-hours\] One participant (Describer) describes an abstract transformation of grids from the [ARC corpus](https://github.com/fchollet/ARC) to another (Builder) using language. The builder applies the transformation on a new input grid to produce an output grid. Access the dataset [here](https://github.com/samacqua/LARC).


---

### DARC: A Recursive Decomposition Dataset of ARC Tasks

<img src="/assets/images/datasets/darc.png" alt="Project Image" width="70%" />

From [ANPL: Towards Natural Programming with Interactive Decomposition
](https://arxiv.org/abs/2305.18498){:target="_blank"}. \[~440 man-hours\] A corpus of 227 ARC tasks, recursively decomposed and grounded as Python code. Access the dataset [here](https://iprc-dip.github.io/ANPL/)

---

### DiffVL100 

<img src="/assets/images/datasets/diffVL.png" alt="Project Image" width="70%" />

From [DiffVL: Scaling Up Soft Body Manipulation using Vision-Language Driven Differentiable Physics](https://arxiv.org/abs/2312.06408){:target="_blank"}. \[~50 man-hours\] 100 soft-body manipulation tasks inspired by real-life scenarios from online videos. Access the dataset [here](https://sites.google.com/view/diffvl/home)